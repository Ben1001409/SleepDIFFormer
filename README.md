<h2 align="center"> <a href="https://openreview.net/forum?id=ftGnpZrW7P">SleepDIFFormer</a></h2>

<h3 align="center"><a href="https://ispamm.github.io/GRAM/"> Project page</a></h3>

<div align=center><img src=assets/gram_method-compresso-1.png width="75%" height="75%"></div>


<h5 align="center">

## ðŸ˜® Highlights

### ðŸ’¡ Radical change in the field of multimodal contrastive learning 
GRAM learns and then aligns modalities directly in the higher-dimensional space in which modality embeddings lie by minimizing the **Gramian volume of the k-dimensional parallelotope spanned by the modality vectors**, ensuring the geometric alignment of all modalities simultaneously.

### ðŸ”¥ SOTA Performance in almost all retrieval task
GRAM can replace cosine similarity in any downstream method, holding for 2 to modality and providing more meaningful alignment with respect to previous similarity measures. Moreover, the novel GRAM-based contrastive loss function enhances the alignment of multimodal models in the higher-dimensional embedding space, leading to new state-of-the-art performance in downstream tasks such as video-audio-text retrieval and audio-video classification.
     
## ðŸš€ Main Results

<div align=center><img src=assets/results.png width="75%" height="75%"></div>
